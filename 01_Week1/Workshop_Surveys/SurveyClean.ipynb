{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from astropy.table import Table, vstack, unique #this package is similar to pandas but personally, I like it more for survey data\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pycountry\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read in your data. os.path.join makes it so that you can type in your path without slashes because windows hates slashes\n",
    "##If you have an excel file or csv file, you can use that with pandas\n",
    "##read_csv from pandas reads in the csv file\n",
    "##Then we turn the data into an astropy Table\n",
    "\n",
    "# #An example to deal with headers in the reading stage\n",
    "# dat=pandas.read_excel(os.path.join('C:','\\\\','Users','elean','Documents','School','Python4STEM','SurveyData.xlsx'), header=0, skiprows=1)\n",
    "# dataA=Table.from_pandas(dat)\n",
    "\n",
    "#An example where you would want the first line to be your column names\n",
    "dat=pandas.read_excel(os.path.join('C:','\\\\','Users','elean','Documents','School','Python4STEM','SurveyData.xlsx'))\n",
    "dataA=Table.from_pandas(dat)\n",
    "\n",
    "# #If you have a header but you don't want spaces in the questions (this is pretty unusual but qualtrics can be annoying with the double header)\n",
    "for i in range(len(dataA.colnames)):\n",
    "    dataA.rename_column(dataA.colnames[i],dataA.colnames[i].replace(\" \",\"\"))\n",
    "\n",
    "data=pandas.read_csv(os.path.join('C:','\\\\','Users','elean','Documents','School','Python4STEM','SurveyData2.csv'))\n",
    "dataB=Table.from_pandas(data)\n",
    "\n",
    "for i in range(len(dataB.colnames)):\n",
    "    dataB.rename_column(dataB.colnames[i],dataB.colnames[i].replace(\" \",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Header problems\n",
    "#We didn't want the data in row 0 (row after the header) so by doing [1:] we tell it to take the data after the 0th row\n",
    "#But before that, we want to store the row 0 for reference because it has the actual questions\n",
    "\n",
    "#By doing the data1[0:0], we created a new table with the same header and the same width as the data1 table\n",
    "qRef=Table(dataA[0:0])\n",
    "#This adds the row with the questions in them to the question reference table\n",
    "qRef.add_row(dataB[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=dataA[1:]\n",
    "data2=dataB[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demonstrating stacking multiple datasets\n",
    "#vstack stacks data vertically so you want to do this when your data have the same columns\n",
    "result=vstack([data1,data2])\n",
    "print(result)\n",
    "result.to_pandas().to_csv(os.path.join('C:','\\\\','Users','elean','Documents','School',\n",
    "                                                       'SurveyDataAll.csv'))\n",
    "\n",
    "#oh no, the data types are different what do we do???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we might try printing the data types of the two tables to visually see the difference\n",
    "print(data1.dtype)\n",
    "print(data2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wow there are a lot of differences\n",
    "#We are just going to change the data types of all columns\n",
    "#Here we are changing everything to a 256 bit string\n",
    "data1=Table(np.array(data1),dtype=['<U256']*len(data1.colnames))\n",
    "data2=Table(np.array(data2),dtype=['<U256']*len(data2.colnames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the data types of the columns you want to stack are the same\n",
    "#Data in columns have to be the same to stack them\n",
    "\n",
    "for colname in data1.colnames:\n",
    "    if colname not in data2.colnames:\n",
    "        print(colname, 'Not in data2')\n",
    "        break\n",
    "    if data1.dtype[colname] != data2.dtype[colname]:\n",
    "        print(data1.dtype[colname], data2.dtype[colname], 'Not the same dtype')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demonstrating stacking multiple datasets\n",
    "#vstack stacks data vertically so you want to do this when your data have the same columns\n",
    "vstackR=vstack([data1,data2])\n",
    "\n",
    "vstackR.to_pandas().to_csv(os.path.join('C:','\\\\','Users','elean','Documents','School','Python4STEM',\n",
    "                                                       'SurveyDataAll.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I forgot what the questions were for the next section, so let's check! Btw this only looks this nice in Jupyter\n",
    "qRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demonstrating selecting specific parts of a dataset by known item\n",
    "#We want only the people who like cookies n' cream, vanilla, chocolate, and other\n",
    "#But we might have a few problems like the n' and capitalization\n",
    "#We must use \"\" instead of '' to deal with the n' and .lower() to deal with the capitalization\n",
    "bestFlavors=Table(vstackR[0:0])\n",
    "for i in range(len(vstackR)):\n",
    "    if vstackR[i]['Q2.4'].lower() in [\"cookies n' cream\", \"vanilla\", \"chocolate\", \"other\"]:\n",
    "        bestFlavors.add_row(vstackR[i])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to know what the flavors are for \"other\" and luckily they added them as text\n",
    "#We can add those flavors that aren't nan to the Q2.4 column so we don't have to keep checking what \"other\" is\n",
    "for i in range(len(bestFlavors)):\n",
    "    if bestFlavors[i]['Q2.4'].lower()=='other':\n",
    "        if bestFlavors[i]['Q2.4_TEXT']!='nan':\n",
    "            bestFlavors[i]['Q2.4']=bestFlavors[i]['Q2.4_TEXT']\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "print(bestFlavors['Q2.4'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#People may have answered the survey more than once. Let's only take the unique response IDs\n",
    "\n",
    "uniqueResponse=unique(bestFlavors, keys=['ResponseId'])\n",
    "print(uniqueResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demonstrating fixing countries\n",
    "#Pretty annoying that people typed in their countries in all different formats. Let's fix that\n",
    "\n",
    "for i in range(len(uniqueResponse)):\n",
    "    try:\n",
    "        country=pycountry.countries.lookup(uniqueResponse[i]['Q2.7'])\n",
    "        uniqueResponse[i]['Q2.7']=country.name\n",
    "        print(uniqueResponse[i]['Q2.7'])\n",
    "    except:\n",
    "        print('Did not recognize ', uniqueResponse[i]['Q2.7'])\n",
    "        uniqueResponse[i]['Q2.7']=input('Please input the country name: ') #This will always be a string\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plotting data\n",
    "###This section makes the plots larger to make it easier to see\n",
    "\n",
    "urPandas=uniqueResponse.to_pandas()\n",
    "\n",
    "urPandas[['Duration(inseconds)','Q2.5']]=urPandas[['Duration(inseconds)','Q2.5']].apply(pandas.to_numeric)\n",
    "\n",
    "\n",
    "plt.scatter(urPandas['Duration(inseconds)'],urPandas['Q2.5'])\n",
    "plt.xlabel(\"Duration in Seconds\")\n",
    "plt.ylabel(\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment analysis has a bunch of different uses and packages the most common being #nltk\n",
    "#https://www.datacamp.com/community/tutorials/simplifying-sentiment-analysis-python\n",
    "# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk\n",
    "# Lexicon-based: count number of positive and negative words in given text and the larger count will be the sentiment of text.\n",
    "# Machine learning based approach: Develop a classification model, which is trained using the pre-labeled dataset of positive, negative, and neutral.\n",
    "\n",
    "#Creates an empty sentiment column\n",
    "# urPandas['sentiment']=\"\"\n",
    "\n",
    "# for i in urPandas['Q2.3']:\n",
    "for i, row in urPandas.iterrows():\n",
    "    blob=TextBlob(urPandas['Q2.3'][i])\n",
    "    sentiment=blob.sentiment.polarity\n",
    "    print(sentiment)\n",
    "    urPandas.loc[i,'sentiment']=sentiment\n",
    "print(urPandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
